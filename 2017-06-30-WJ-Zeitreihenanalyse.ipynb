{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zeitreihenanalysen mit R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In diesem Abschnitt werden grundlegnde Definitionen zum näheren Verständnis der Zeitreihenanalyse gegeben. Die Zeitreihenanalyse ist ein sehr mathematisch geürägtes Feld der deskriptiven Statistik und breit gefächert. Zudem kann die Analyse von Zeitreihen  eine gewisse tiefe Vorweisen. im folgenden wird deshalb nur eine Einführung in die zentralen Komponenten und Konzepte der Zeitreihenanalyse gegeben. Für eine tiefgreifendere Auseinandersetzung wird an dieser Stelle auf die am Ende dieses Kapitels benannten Literaturquellen verwiesen.\n",
    "\n",
    "Es müssen zunächst einige zentrale Definitionen gegeben und Begriffsabgrenzungen gemacht werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grundlegende Definitionen und Prozesse\n",
    "\n",
    "Unter einem stochastischen Prozess versteht man eine Folge $(Y_t)$ von Zufallsvariablen. Der Index $t$ wird hier als die Zeit aufgefasst.  **Eine Zeitreihe ist eine (geordnete) Folge von $ y_1,...,y_n $ von Realisationen eines Ausschnittes von $(Y_t)$ Beobachtungen.** Man nennt diese oft auch *Zeitpfad* oder *Trajektorie* des Prozesses.\n",
    "Ein wichtiges Charakteristikum stellt hierbei die Unabhängigkeit der Beobachtungen dar. Zudem sollten die Beobachtungen $ y_{t1},...,y_{tk}  \\in Y_t$  äquidistant sein.\n",
    "\n",
    "Weiterhin werden ein *White-Noise-Prozess* (s. auch [wikipedia](https://de.wikipedia.org/wiki/Wei%C3%9Fes_Rauschen)), sowie die *Normalverteilung* vorausgesetzt. Unter einem White-Noise_prozess versteht man eine Folge von unabhängigen und identisch verteilten (Zufalls-)Variablen. Bei Zufallsprozessen, zu welchen auch der *Random Walk* zählt, spricht man auch von Zufallsvariablen ($\\epsilon_t$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Analyse von Zeitreihen hat das Ziel, Strukturen und Regelmäßigkeiten in Zeitreihen aufzuspüren und zur Beschreibung und Modellierung auszunutzen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeitreihenanalysen eignen sich für folgende Anwendungsbereiche:\n",
    "\n",
    "| Anwendungsfeld | Beispiel            |\n",
    "| :------------- |:-------------|\n",
    "|Beschreibung| **Komponentenmodell** |\n",
    "|Interpretation|**Saisonbereinigung**|\n",
    "|Prognose|**Verkaufs-/Umsatzzahlen im kommenden Quartal**|\n",
    "|Kontrolle|Kontrolle eines Produktionsprozesses|\n",
    "|Hypothesentest|Überprüfung von Hypothesen: *Gibt es die Globale Erwärmung?*|\n",
    "|Simulation|Simulation verschiedener Szenarien, z.B. Preiveränderung|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretischer Hintergrund"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst soll das Rahmenwerk, welches zum tieferen Verständnis der Zeitreihenanalyse erforderlich ist, erläutert werden. Hierbei wird auf den oben genannten Begriffsklärungen aufgebaut und zunächst ein typisches Vorgehensmodell zur Datenanalyse auf Zeitreihen gegeben. Darauffolgend sollen die einzelnen Phasen erläutert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationarität und Ergodiszität\n",
    "\n",
    "Eine grundlegnde Annahme bei der Zeitreihenanalyse ist die *Stationarität*. Hierunter versteht man die Eigenschaft, dass sich die stochastischen Charakteristika über die Zeit nicht ändern. Eine Zeitreihe ist stationär, wenn sich die grundlegenden Charakteristika (Mittelwerte, Varianzen, etc.) über die Zeit nicht wesentlich voneinander abweichen. Ist die Stationarität anfangs nicht gegeben, so muss diese zunächst hergestellt werden. Dies geschieht durch das bilden von Differenzen oder durch logarithmieren. \n",
    "Man erhält eine stationäre Zeitreihe durch das bilden der ersten oder ggf. weiteren Differenzen. Unter der Differenzbildung versteht man die Berechnung der Wertveränderung zwischen zwei Beobachtungen, also $$y'_t = y_t - y_{t-1}$$\n",
    "Ist der gegebene Prozess bereits stationär, so spricht man von einem Prozess, welcher vom Grad *null* integriert ist ($I(0)$). Ist dies nicht der Fall, so sind es die ersten Differenzen $\\Delta Y_t = Y_t - Y_{t-1}$. Der Prozess weist somit den Grad *eins* auf. Bei ökonoischen Zeitreihen, wie sie auch hier behandelt werden genügt meist ein Grad eins ($I(1)$) zur Herstellung der Stationarität.\n",
    "\n",
    "Für die Überprüfung stehen verschiedene *Einheitswurzeltests*, wie zum Beispiel der [*Augmented Dickey-Fuller* Test](https://de.wikipedia.org/wiki/Dickey-Fuller-Test) zur Verfügung.\n",
    "\n",
    "</br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine weitere Voraussetzung ist die *Ergodiszität*. Hierunter versteht man grob gesagt die Forderungen, dass sich alle Charakteristika der Verteilung je endlich vieler Zufallsvariablen $y_{t1},...,y_{tk}$ konsistent schätzen lassen. Hierbei geht es konkret um aus dem zeitlichen Verlauf bestimmte Größen wie Varianz und Kovarianz wie auch Erwartungswerte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wichtige Modelle - Ein Überblick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Modell |            |\n",
    "| :------------- |:-------------|\n",
    "|Autoregressive Prozesse                            |(**AR**-Prozess)   |\n",
    "|Moving Average Prozesse                            |(**MA**-Prozess)   |\n",
    "|Autoregressive Moving Average Prozesse             |(**ARMA**-Prozess) |\n",
    "|Autoregressive Integrierte Moving Average Prozesse |(**ARIMA**-Prozess)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Das Komponentenmodell\n",
    "\n",
    "Ein Komponentenmodell ist ein grundlegender Schritt bei der Analyse von Zeitreihen. Für ein Komponentenmodell wird die nicht-stationäre Ausgangszeitreihe in die Bestandteile Trend-, Saison-, Zyklische sowie die Irreguläre Komponente (Random) zerlegt. Ziel ist es, die genauen Bestandteile und Einflussgrößen näher betrachten zu können. So kann beispielsweise bei Produktabsatzzahlen ein (meist) linearer Trend beobachtet werden. Weiterhin unterliegt der Absatz sehr wahrscheinlich saisonalen Einflüssen wie Schulferien und bestimmte Jahreszeiten (z.B. Weihnachtsgeschäft). Die Zyklische Komponente (auch *Kalenderkomponente*) stellt bei ökonomischen Zeitreihen meist noch den Konjunkturzyklus als Einflussgröße dar. Unter dem irregulären Rest versteht man den nicht durch die vorangegangenen Komponenten erklärbare, auf stochastischen Prozessen (s.o.) beruhende Einflüsse auf die Zeitreihe. Im Idealfall liegt hier ein White-Noise- oder Random-Walk-Prozess vor.\n",
    "\n",
    "Grundsätzlich unterstellt man einer (ökonomischen) Zeitreihe ein Zerlegung nach additiver oder multiplikativer Form, wobei $$ Y_t = T_t + S_t + \\epsilon_t  \\text{(Additiv)}$$ \n",
    "$$ Y_t = T_t \\cdot S_t \\cdot \\epsilon_t \\text{(Multiplikativ)}$$ \n",
    "bezeichnet wird.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trend\n",
    "\n",
    "Unter einem Trend wird zunächst eine Grundentwicklung von Beobachtungen über die Zeit verstanden. Zur Bestimmung eines Trends wird in erster Linie die bereits bekannte lineare Regression verwendet.\n",
    "Bei Zeitreihen, welche unter dem Einfluss einer oder mehrerer saisonaler (z.B. Jahreszeiten) und zyklischer Einflüsse (z.B. Konjunktur) stehen, gestaltet sich die Ermittlung eines deterministischen Trends durch die teils erheblichen Schwankungen (Trendbrüche) als schwierig. Für diesen erweiterten Rahmen wird der Trend ökonischer Zeitreihen oft auch als *glatte Komponente* bezeichnet. Die glatte Komponente $G_t$ unterscheidet sich vom gewöhnlichen deterministischen Trend durch die Berücksichtigung des Zyklus $Z_t$; somit ergibt sich die Gleichung: \n",
    "$$G_t = T_t + Z_t$$\n",
    "\n",
    "Bei der Bestimmung der glatten Komponente hat sich hier die Methodik der gleitenden Durchschnitte (Moving Averages) durchgesetzt. Die Methode der gleitenden Durchschnitte zählt zur Kategorie der *linearen Filter*. Hierbei wird der deterministische Trend durch lokale Mittelwerte geschätzt. Hierbei werden arithmetische Mittelwerte zu vordefinierten Segmentgrößen ermittelt und einem bestimmten Zeitpunkt zugeordnet. Hierbei wird die Segmentgrße $d$ stets *ungerade* gewählt. Gleitende Durchschnitte werden folgendermaßen berechnet: $$ \\sum_{t=s+1}^{s+d}\\frac{y_t}{d} $$\n",
    "\n",
    "Wobei $d$ die Segmentgröße darstellt. Somit wird der Mittelwert dem Zeitpunkt $s+\\frac{d+1}{2}$ zugeordnet.\n",
    "\n",
    "Eine weitere Möglichkeit zur Interpolation der glatten Komponente bieten [splines](https://de.wikipedia.org/wiki/Spline-Interpolation), welche an dieser Stelle aber nicht näher betrachtet werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saison\n",
    "\n",
    "Die Saison ist als ein periodisch wiederkehrendes Phänomen definiert. Saisonale Einflüsse können je nach Granularität einer Beobachtungungsreihe wöchentlich, monatlich oder quartals- bzw. jahresweise auftreten. Ebenso kann die Jahreszeit die Beobachtungen beeinflussen. In einer Zeitreihe können mehrere saisonale effekte auftreten.\n",
    "Bei der Zerlegung öhonomischer Zeitreihen spielt die Saisonbereinigung, also das herausrechnen dieser wiederkehrenden Größe, eine wichtige Rolle. In der retrospektiven Komponentenzerlegung dient die Saisonbereinigung dem Ziel einer besseren und klareren Einschätzung der momentanen Situation.\n",
    "\n",
    "Wichtige Saisonbereinigungsverfahren sind das *Berliner Verfahren* (BV4.1), *X-12 ARIMA*, sowie *CENSUS X-11*. Diese Modelle werden für die makroökonomischen Analysen des Statistischen Bundesamtes und dergleichen in aller Welt angewandt.\n",
    "\n",
    "Diese Modelle sind sehr speziell und in an dieser Stelle nicht darstellbar. Es reicht (für uns) diese Modellbezechnungen und deren Existenz zu kennen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregressive Modelle (AR)\n",
    "\n",
    "Das grundlegende Bestreben bei einer Zeitreihenanalyse ist das Erklären und Verstehen der Zeitreihen. Bei Autoregressiven Prozessen (bzw. Modellen) wird angenommen, dass sich die Ausprägung eines Wertes $Y_t$ aus den vorhergegangenen Werten $y_{t-1}...y_{t-n}$ der Zeitreihe ergeben. Man kann somit folgende Funktion unterstellen:\n",
    "$$ Y_t = f(y_{t-1}...y_{t-n}) + \\epsilon_t$$\n",
    "\n",
    "Hierbei beruht die Funktion $f$ auf einer linearkombination der zeitlich vorangegangenen Werte. Dies erfolgt bis zu einem sinnvoll begründeten Vergangenheitshorizont. Das autoregressive Modell wird somit durch folgende Gleichung festgelegt:\n",
    "$$ Y_t = \\alpha_0 + \\alpha_1 Y_{t-1}+...+\\epsilon_t$$\n",
    "\n",
    ">Ein autoregressiver Prozess erster Ordnung (AR(1)), ist demzufolge ein stochastischer Prozess, dessen Realisation im Zeitpunkt $t$, $Y_t$, nur von seiner mit $\\alpha_1$ gewichteten Realisation im Zeitpunkt $Y_{t-1}$ und einem weißen Rauschen $\\epsilon_t$ abhängt, d.h. $ Y_t = \\alpha_0 + \\alpha_1 Y_{t-1}+\\epsilon_t$ gilt. (vgl. [Gabler Wirtschaftslexikon](http://wirtschaftslexikon.gabler.de/Definition/ar-p-prozess.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die entscheidende Größe für die Charakterisierung der Eigenschaften von AR-Prozessen ist die Autokorellationsfunktion, kurz [ACF](https://de.wikipedia.org/wiki/Autokorrelation).\n",
    "\n",
    "Um die Ordnung $p$ eines AR-Prozesses zu bestimmen kann im Plot der Autokorrelationsfunktion nach einem bestimmten Muster 'gesucht' werden. Folgendes Charakteristikum gilt beispielsweise für einen AR(p)-Prozesse:\n",
    "* ACF klingt nach Lag $p$ exponentiell ab.\n",
    "\n",
    "Weiterhin gibt es die Möglichkeit, die Ordnung $p$ eines AR-Prozesses mit der Hilfe eines Informationskriteriums sukzessive (durch ausprobieren) zu ermitteln. Hierzu gibt es beispielsweise das [AIC](https://en.wikipedia.org/wiki/Akaike_information_criterion) (* **A**kaike **I**nformation **C**riterion*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Average Modelle (MA)\n",
    "\n",
    "Die MA-Prozesse gehören zu einer anderen Gattung als die AR-Prozesse. MA-Prozesse beziehen sich nicht auf die vergangenen Werte von $Y_t$ sondern auf die zurückliegenden Störungen $\\epsilon_t$. Es ergibt sich somit folgende, charakteristische Gleichung:$$ Y_t = \\epsilon_t - \\epsilon{t-1}+...+\\epsilon_{t-q}$$ wobei $q$ die Ordnung des Prozesses angibt. Im Gegensatz zu AR-Prozessen wird hier lediglich eine Summe gewichteter Zufallsvariablen gebildet. Somit sind MA-Prozesse stets (schwach) stationär.\n",
    "\n",
    "Um die Ordnung $q$ eines MA-Prozesses zu bestimmen kann im Plot der Autokorrelationsfunktion, sowie der partiellen Autokorrelationsfunktion nach einem bestimmten Muster 'gesucht' werden. Folgende Charakteristika gelten für MA(q)-Prozesse:\n",
    "* ACF verschwindet für Lags $\\tau$, welche größer als die Ordnung des Prozesses sind.\n",
    "* PACF ist für $\\tau$ > $q$ exponentiell abklingend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregressive Integrierte Moving Average Modelle (ARIMA)\n",
    "\n",
    "Das Autoregressive Integrierte Moving Average Modell, kurz ARIMA, besteht aus den drei, uns bereits bekannten, Komponenten: Der Grad der Differenz $d$, dem AR(p)-Modell und dem MA(q)-Modell. Man spricht vor diesem Hintergrund auch von ARIMA(p,d,q)-Modellen. Dieses Modell geht auf [Box und Jenkins](https://en.wikipedia.org/wiki/Box%E2%80%93Jenkins_method) zurück und ist eine Erweiterung des ARMA-Modells. Die Erweiterung besteht im wesentlichen darin, dass für ARIMA-Modelle keine stationarität vorausgesetzt wird. Die Zeitreihe kann also bewusst eine Trendkomponente beinhalten.\n",
    "In der Erweiterung SARIMA (S steht für seasonal) wird das eigentliche Modell noch um eine Saisonkomponente erweitert und ermöglicht somit neue Freiheitsgrade.\n",
    "\n",
    "Die Grade $p$,$d$,$q$ können mit Hilfe der [*Box-Jenkins Methode*](https://en.wikipedia.org/wiki/Box%E2%80%93Jenkins_method) fundiert geschätzt und daraus resultierende Modell letztlich mittels Informationskriterien (*AIC*,*BIC*) evaluiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Praktischer Hintergrund"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Für die Zeitreihenanalyse werden wir die Pakete [forecast](https://cran.r-project.org/web/packages/forecast/ \"forecast\"), [tseries](https://cran.r-project.org/web/packages/tseries/ \"tseries\") verwednen. Weiterhin soll [ggplot2](https://cran.r-project.org/web/packages/ggplot2/ \"ggplot2\") zur Visualiserung herangezogen werden. Im nachfolgenden soll das theoretisch besprochene am Beispiel des **bike sharing** Datensatzes veranschaulicht werden. Der Datensatz stammt aus dem frei zugänglichen Repository des [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset# \"UCI\").\n",
    "\n",
    "Als Referenz dient für die folgenden Schritte die Analyse von [datascience.com](https://www.datascience.com/blog/introduction-to-forecasting-with-arima-in-r-learn-data-science-tutorials), welche die Grundalge für weitere Analysen in diesem notebook bildet.\n",
    "\n",
    "\n",
    "> Folgende Pakete werden benötigt: Diese müssen gegebenenfalls zunächst installiert werden, da nicht alle im Standard enthalten sind.\n",
    "In Windows-Kommandozeile:>> conda install r-forecast (Die Installation von forecast bringt automatisch auch tseries mit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library('zoo')      #benötigt von ggplot2\n",
    "library('timeDate') #benötigt von ggplot2\n",
    "\n",
    "library('ggplot2')\n",
    "library('forecast')\n",
    "library('tseries')\n",
    "\n",
    "\n",
    "bikes = read.csv('Bike-Sharing-Dataset/day.csv', header=TRUE, stringsAsFactors=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phase 1: Erste Überprüfung der Zeitreihe\n",
    "\n",
    "Im ersten Schritt müssen wir den ursprünglichen Datensatz um einen Tag erweitern. Hierdurch wird uns die weitere Arbeit mit dem Datensatz durch einfaches parsen (Funktion as.Date) erleichtert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes$Date = as.Date(bikes$dteday) #notwendig um Datenformat 'Date' zu erhalten.\n",
    "\n",
    "ggplot(bikes, aes(Date, cnt)) + geom_line() + scale_x_date('Monat')  + ylab(\"Entliehene Räder\") +\n",
    "            xlab(\"\") + scale_y_continuous(limits = c(0, 20000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dem Plot kann man folgende Charakteristika entnehmen:\n",
    "* Der Datensatz repräsentiert eine womöglich **markant saisonal** geprägte Zeitreihe.\n",
    "\n",
    "* Der Datensatz weist einen **positiven Trend** über den abgebildeten Zeitraum (2011-2013) auf.\n",
    "\n",
    "* Der Datensatz zeigt **teils erhebliche Schwankungen/Ausschläge**, vor Allem in der rechten Hälfte auf.\n",
    "\n",
    "* Der Datensatz gibt zudem Hinweise auf **mögliche Fehlmessungen im Mai-2012 und Oktober-2013.**\n",
    "\n",
    "\n",
    "Diesen enormen negativen Ausschlag im Oktober 2013 sollten wir uns einmal genauer ansehen. Durch die manuelle Suche konnten wir diesen auf die letzte Oktoberwoche eingrenzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes[666:670, c(\"cnt\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie wir hier sehr deutlich sehen können, muss es sich hier um eine Fehlmessung und somit um einen Ausreisser handeln. Da wir keine weiteren Informationen diesbezüglich haben, werten wir den Datensatz 668 als Ausreisser. Hier wäre zur absolut korrekten Interpretation eine Nachfrage im Fachbereich angebracht. \n",
    "\n",
    "Im Paket tseries gibt es für diese Aufgabe die Methode tsclean(). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_ts = ts(bikes[, c('cnt')])\n",
    "\n",
    "bikes$clean_cnt = tsclean(bikes_ts)\n",
    "\n",
    "ggplot()+ geom_line(data = bikes, aes(x = Date, y = clean_cnt)) + xlab('Zeitraum') + ylab('Entliehene Räder (bereinigt)') + scale_y_continuous(limits = c(0, 20000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als nächstes werden wir die Zeitreihe um die teils erheblichen Ausschläge und Schwankungen ausgleichen. Dies ist notwendig um bessere Vorhersagen zu machen. In diesem Zusammenhang haben sich die **gleitenden Durchschnitte** (Moving Average, MA) bewährt. Wir wenden im folgenden die Funktion **ma()** aus dem Paket tseries an.\n",
    "\n",
    "Für die vorliegende Zeitreihe bieten sich aufgrund des beschränkten Beobachtungszeitraums von 2 Jahren nur die gleitenden Durchschnitte der Ordnung 7 (Kalenderwoche) und 30 (Kalendermonat) an.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes$cnt_ma = ma(bikes$cnt, order=7)\n",
    "bikes$cnt_ma30 = ma(bikes$cnt, order=30)\n",
    "\n",
    "\n",
    "ggplot(colour = \"black\") +\n",
    "  geom_line(data = bikes, aes(x = Date, y = clean_cnt)) + \n",
    "  geom_line(data = bikes, aes(x = Date, y = cnt_ma, colour = \"ma(7)\"), size = 1)    +\n",
    "  geom_line(data = bikes, aes(x = Date, y = cnt_ma30, colour = \"ma(30)\"), size = 1) +\n",
    "  ylab('Entliehene Räder') + scale_y_continuous(limits = c(0, 20000)) +  scale_color_brewer(palette=\"Dark2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im folgenden entscheiden wir uns für die präzisere Variante des ma(7).\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Phase 2: Die Komponentenzerlegung\n",
    "\n",
    "Als nächstes werden wir die Komponentenzerlegung durchführen. Hier wird die Zeitreihe in die Bestandteile Trend, Saison und den zufälligen Rest zerlegt. Durch die Zerlegung können wir einen tieferen Einblick in die Zeitreihe nehmen und diese schlißelich besser verstehen. Die Komponentenzerlegung bildet die Grundlage für die Wahl des richtigen Prognosemodells.\n",
    "\n",
    "Mit Hilfe der Funktion seasadj() aus dem Paket forecast können wir auf einfache Weise die Saisonbereinigung durchführen. Hierbei wird die Saison aus dem Komponentenmodell von der ursprünglichen Zeitreihe subtrahiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_ma = ts(na.omit(bikes$cnt_ma), frequency=30)\n",
    "decomp = decompose(count_ma)\n",
    "deseasonal_cnt = seasadj(decomp)\n",
    "plot(decomp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für unser gewünschtes Prognosemodell (ARIMA) wird, wie bereits im theoretischen Teil genannt, auch die Stationarität der Zeitreihe vorausgesetzt. Ein geschultes Auge kann meist aus dem ursprünglichen Plot erkennen, ob die Zeitreihe Stationarität aufweist.\n",
    "Zur sicheren Überprüfung gibt es sogenannte Einheitswurzeltests. Diese führen einen Hypothesentest auf der gegebenen Reihe aus.\n",
    "\n",
    "Wir wenden hier den Augmented Dickey-Fuller Test (ADF) Test an. Hierbei übergeben wir unsere Zeitreihe und legen die Alternativ-Hypothese \"stationarity\" fest. Beim ADF-Test wird somit mit H0 die nicht-stationarität angenommen und überprüft. Im besten Fall gibt uns dieser Test dann eine sehr niedrige Wahrscheinlichkeit (s. p-value) aus. (p-value bewegt sich zwischen 0 und 1!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.test(count_ma, alternative = \"stationary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phase 3: Herstellen der Stationarität\n",
    "\n",
    "Zunächst müssen wir jedoch die Stationarität unserer Zeitreihe herstellen. Hierbei greifen wir auf die bereits saisonbereinigte Zeitreihe deaseasonal_cnt zurück. Die Herstellung der Stationarität wird durch geeignetes transformieren hergestellt. Im wesentlichen gescheiht das durch die bereits erwähnte Differenzenbildung. Hierfür gibt es die Funktion diff() aus dem Paket forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_d1 = diff(deseasonal_cnt, differences = 1)\n",
    "plot(count_d1,  main = \"Zeitreihe (differenziert)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach der Transformation wenden wir erneut den ADF-Test an. Hierdurch soll überprüft werden, ob die Stationarität durch die einfache Differenzenbildung erfolgreich hergestellt werden konnte. Sollte hier weiterhin die Hypothese der nicht-stationarität gestützt werden, so ist womöglich eine nochmalige Differenzenbildung notwendig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressWarnings(adf.test(count_d1, alternative = \"stationary\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsere Zeitreihe ist nun stationär. Wir können uns folglich dem Aufbau und dem Fitting des Prognosemodells widmen. (ARIMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Phase 4: ACF, PACF und die Wahl des Grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der Funktion tsdisplay() (ggplot: ggtsdisplay) erhält man eine kleine Übersicht über die Zeitreihe. Hier werden zusätzlich zum Plot der übergebenen Zeitreihe auch die dazugehörigen **ACF**- und **PACF**-Plots ausgegeben. Wie bereits im theoretischen Teil erklärt erhalten wir mit dem **ACF**-Plot eine Aussage bzw. Darstellung über die Korrelation zwischen Zeitreihe und den dazugehörigen Lags.\n",
    "Mit dem **PACF**-Plot werden Zusammenhänge deutlich, welche zwischen Variable und Lag bestehen und *nicht* durch vorangegangene Lags erklärt werden können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie man aus dem ACF-Plot (s.u.) entnehmen kann bestehen wesentliche Autokorellationen. **TODO**\n",
    "Der PACF-Plot gibt uns erste Vorschläge über den Grad des zu wählenden ARIMA-Modells. Hier stechen die sehr markanten Ausreisser zum Lag 1, 2 und 7 im PACF-Plot ins Auge. Des Weiteren lässt sich eine wellenartiges Muster mit widerkehrenden Ausreissern mit Periode 7 beobachten. Dies deutet auf einen verbliebenen saisonalen Einfluss hin, welcher uns aber im folgenden nicht weiter stört."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsdisplay(count_d1, main = \"Analyse der differenzierten Zeitreihe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phase 5: Fitting ARIMA\n",
    "\n",
    "Wie die vorangegangene Untersuchung der ACF- und PACF-Plots gezeigt hat, sind die Grade 1, 2 und 7 geeignete Kandidaten für unser aufzustellendes Modell. Im folgenden soll nun ein ARIMA-Modell aufgestellt und bewertet werden. Hierzu verwenden wir die Funktion arima() aus dem Paket forecast. \n",
    "\n",
    "> *(In diesem Paket ist auch die Funktion auto.arima() enthalten, welche uns zwar das manuelle Fitting abnimmt, jedoch keinen Lerneffekt beinhaltet. Dazu zum Schluss mehr.)*\n",
    "\n",
    "Im vorliegenden Fall soll demnach der Grad manuell bestimmt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_arima_111 = arima(deseasonal_cnt, order=c(1,1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der naheliegendste Fall ist unter Berücksichtung der Ergebnisse unserer Untersuchung in Phase 4 der Grad 1,1,1. Mit dem Attribut lag.max wird die maximal auszugebende Anzahl geplotteter Lags im ACF- und PACF-Plot gesteuert. Hier ist es notwendig, einen passenden Wert zu ermitteln. Mit lag.max=50 können wir im PACF-Plot ein Muster erkennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsdisplay(residuals(fit_arima_111), lag.max=50, main= \"Analyse ARIMA(1,1,1)-Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der PACF-Plot zeigt ein Muster an jedem siebten Lag. Dies legt die Entscheidung nahe, das Modell auf q = 7 anzupassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_arima_117 = arima(deseasonal_cnt, order=c(1,1,7))\n",
    "tsdisplay(residuals(fit_arima_117), lag.max=15, main=\"Analyse ARIMA(1,1,7)-Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier sehen wir weder beim ACF-Plot noch beim PACF-Plot Auffälligkeiten. Welches der beiden Modelle ist nun für unsere Prognose besser? Um dies zu bewerten gibt es den AIC (*Akaike Information Criterion*) und BIC(*Bayesian Information Criterion*) Wert. AIC und BIC sind ein Maß für den Informationsgehalt, welcher verloren geht. Diese Kennzahlen sind nur im direkten Vergleich zwischen Modellen aussagefähig. Je kleiner/negativer der Wert, desto besser ist das Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_arima_111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_arima_117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie man den beiden AIC-Werten entnehmen kann ist das Modell mit der Ordnung (1,1,7) besser als jenes der Ordnung (1,1,1). Im folgenden werden wir nun die Prognose mittels der Funktion forecast() erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = forecast(fit_arima_117, h=30)\n",
    "plot(prediction, main = \"Prognose aus ARIMA(1,1,7)-Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix: Testen & Verbesserung des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ergebnis unserer Prognose ist oben in blauer Farbe zu sehen. Wie präzise ist unsere Vorhersage? Eine einfache Methode wäre hier das aussparen eines Monats am Ende der Zeitreihe. Diesen Teil lassen wir uns von ARIMA prognostizieren und bekommen durch den Vergleich mit den vorliegenden, zurückgehaltenen Daten einen EIndruck von der Güte des Modells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = window(ts(deseasonal_cnt), start=700)\n",
    "\n",
    "fit_train = arima(ts(deseasonal_cnt[-c(700:725)]), order=c(1,1,7))\n",
    "\n",
    "prediction_test <- forecast(fit_train,h=25)\n",
    "plot(prediction_test, main=\"Prognose aus ARIMA(1,1,7)-Model mit window\", ylim=c(0,8000))\n",
    "lines(ts(deseasonal_cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie man unschwer erkennt ist hier eine gewisse Abweichung zu verzeichnen. Auch fällt es auf, dass die Prognose quasi waagerecht verläuft. Dies ist schlichtweg falsch, da man in der vorliegenden Zeitreihe zu keinem Zeitpunkt einen waagerechten Verlauf verzeichnet hat. Das Verhalten lässt sich zweifelsfrei dadurch erklären, dass hier saisonale Einflüsse nicht berücksichtigt werden (können). Des Weiteren wird hier 'nur' die Zeit berücksichtigt. Der Verleih von Fahrrädern unterliegt neben saisonalen Schwankungen (z.B. Jahreszeit) auch weiteren EInflüssen, wie dem Wetter.\n",
    "\n",
    "Das ARIMA-Modell kann hierfür als Ausgangsbasis herangezogen werden. Exemplarisch wollen wir an dieser Stelle noch eine Saison in das Modell rückführen. Hierbei wird auf das Attribut *seasonal* der Funktion auto.arima() zurückgegriffen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_auto = auto.arima(deseasonal_cnt, seasonal=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_seasonal = forecast(fit_auto, h=30)\n",
    "plot(prediction_seasonal,  main = \"Prognose aus ARIMA(2,1,1)-Model mit Saison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_auto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vergleichen wir abschließend den AIC Wert mit unseren beiden anderen Modellen, so sehen wir, dass auto.arima uns zwar das manuelle Fitting ersparen kann, jedoch nicht das optimale Modell ermittelt. Die Prognose ist unter Hinzunahem der Saison jedoch deutlich realistischer geworden. Hierauf könnte weiter aufgebaut werden. Abschließend sollte erwähnt werden, dass ARIMA-Modelle am besten zur Prognose auf Zeitreihen mit relativ geringen Ausschlägen angewendet werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Verwendete Literatur:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schlittgen, R. (2015). Angewandte Zeitreihenanalyse mit R. München/Berlin/Boston: Walter de Gruyter GmbH.\n",
    "\n",
    "Backhaus, K., Erichson, B., Plinke, W., Weiber, R. (2016). Multivariate Analysemethoden. Berlin/Heidelberg: Springer Gabler.\n",
    "\n",
    "Heinrich, G. (2012). Basiswissen Mathematik, Statistik und Operations Research für Wirtschaftswissenschaftler. München: Oldenbourg Wissenschaftsverlag GmbH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verwendetes Datenset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
